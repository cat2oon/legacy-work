{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TED Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from generator.generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = np.load('/Volumes/SSD3/everyone-faze-recode/profile-recode-00005.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_config():\n",
    "    return {\n",
    "        'densenet_growthrate' : 32,\n",
    "        'z_dim_app' : 64,\n",
    "        'z_dim_gaze' : 2, \n",
    "        'z_dim_head' : 16,\n",
    "        'decoder_input_c' : 32,\n",
    "\n",
    "        'normalize_3d_codes' : True,     \n",
    "        'normalize_3d_codes_axis': 1,\n",
    "\n",
    "        'triplet_loss_type' : 'angular',   # or euclidean\n",
    "        'triplet_loss_margin' : 0.0,\n",
    "        'triplet_regularize_d_within' : True,\n",
    "\n",
    "        'all_equal_embeddings': True,\n",
    "        'embedding_consistency_loss_type' : None, # angular, euclidean\n",
    "        'embedding_consistency_loss_warmup_samples' : 1000000,\n",
    "\n",
    "        'backprop_gaze_to_encoder' : True,\n",
    "\n",
    "        'coeff_l1_recon_loss' : 1.0,\n",
    "        'coeff_gaze_loss' : 0.1,\n",
    "        'coeff_embedding_consistency_loss' : 2.0, \n",
    "\n",
    "        # 0이 아닌 값들은 윈도우 쥬피터 노트북에서 parallel broken pipe\n",
    "        'num_data_loaders' : 8,     \n",
    "        'pin_memory': False,\n",
    "        #  'batch_size' : 32,\n",
    "        'batch_size' : 64,\n",
    "        # 'batch_size' : 256,\n",
    "        'use_apex' : False,\n",
    "        'base_lr': 0.0005,\n",
    "        'warmup_period_for_lr' : 1000000, \n",
    "        \n",
    "        'decay_interval' : 0,\n",
    "        'decay' : 0.8,\n",
    "        'num_training_epochs' : 20,\n",
    "        'l2_reg' : 1e-4,\n",
    "        'print_freq_train' : 20,\n",
    "        'print_freq_test' : 5000,\n",
    "\n",
    "        # 프로파일별 불균형 허용되도록 아래 옵션 사용 안함\n",
    "        # 'pick_exactly_per_person' : None, 'pick_at_least_per_person' : 400,\n",
    "        \n",
    "        # 'resource_path': '/Volumes/SSD3/faze-resources/',\n",
    "        # 'npz_root_path': '/Volumes/SSD3/everyone-faze-sample/',\n",
    "        \n",
    "        'resource_path': '../../../../../panny/vcubuntu3/data-archive/faze-resources/',\n",
    "        'npz_root_path': '../../../../../panny/vcubuntu3/data-archive/faze-recode-profile-npz/',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "config = get_mock_config()\n",
    "Context.build(config)\n",
    "ctx = Context.get()\n",
    "\n",
    "print(ctx.z_dim_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TED(\n",
    "    growth_rate=ctx.densenet_growthrate,\n",
    "    z_dim_app=ctx.z_dim_app,\n",
    "    z_dim_gaze=ctx.z_dim_gaze,\n",
    "    z_dim_head=ctx.z_dim_head,\n",
    "    decoder_input_c=ctx.decoder_input_c,\n",
    "    normalize_3d_codes=ctx.normalize_3d_codes,\n",
    "    normalize_3d_codes_axis=ctx.normalize_3d_codes_axis,\n",
    "    use_triplet=ctx.triplet_loss_type,\n",
    "    backprop_gaze_to_encoder=ctx.backprop_gaze_to_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.set_network('ted', network)\n",
    "ctx.load_network_to_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Base Loss Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 04:10:37,937 >>> base lose policy <<<\n",
      "2020-01-23 04:10:37,938 max learning rate: 0.032000\n",
      "2020-01-23 04:10:37,938 ramp up a: 0.000002, b: 0.000500\n"
     ]
    }
   ],
   "source": [
    "ctx.setup_base_loss_policy(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 04:10:37,957 Set optimizer as key: optimizer\n",
      "2020-01-23 04:10:37,958 Set optimizer as key: gaze_optimizer\n"
     ]
    }
   ],
   "source": [
    "optimizer, gaze_optimizer = ctx.build_optimizer('ted')\n",
    "ctx.set_main_optimizer(optimizer)\n",
    "ctx.set_gaze_optimizer(gaze_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 04:10:37,963 >>> Setup loss functions\n",
      "2020-01-23 04:10:37,963 list: { gaze, recon_l1, triplet, all_equal } \n"
     ]
    }
   ],
   "source": [
    "loss_functions = ctx.make_loss_functions()\n",
    "ctx.set_loss_functions(loss_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 04:10:38,988 \n",
      ">>> Data-Generator prepared <<<\n",
      "2020-01-23 04:10:38,989 [gc/train] full set size:           1797228\n",
      "2020-01-23 04:10:38,989 [gc/train] current set size:        1797228\n",
      "2020-01-23 04:10:38,989 [gc/train] num people:                 1274\n",
      "2020-01-23 04:10:38,990 [gc/train] mean entries per person:    1410\n",
      "2020-01-23 04:10:38,990 \n",
      "2020-01-23 04:10:38,990   [gc/val] full set size:             81280\n",
      "2020-01-23 04:10:38,990   [gc/val] current set size:          81280\n",
      "2020-01-23 04:10:38,991   [gc/val] num people:                   50\n",
      "2020-01-23 04:10:38,991   [gc/val] mean entries per person:    1625\n",
      "2020-01-23 04:10:38,991 \n",
      "2020-01-23 04:10:38,991  [gc/test] full set size:            251472\n",
      "2020-01-23 04:10:38,992  [gc/test] current set size:         251472\n",
      "2020-01-23 04:10:38,992  [gc/test] num people:                  150\n",
      "2020-01-23 04:10:38,992  [gc/test] mean entries per person:    1676\n",
      "2020-01-23 04:10:38,992 \n",
      "2020-01-23 04:10:38,993 >>> data-bag is setup\n",
      "2020-01-23 04:10:38,993 => { gc/train, gc/val, gc/test } \n"
     ]
    }
   ],
   "source": [
    "gen = NPZDatasetGenerator(ctx, shuffle_train=False)\n",
    "databag = gen.generate(verbose=True)\n",
    "ctx.set_databag(databag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, loader = ctx.get_dataset_and_loader(Context.TAG_TRAIN)\n",
    "# print(train_ds.profiles)\n",
    "# print(len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#  DataLoader iter 돌다가 \n",
    "#  expected Tensor as element 1 in argument 0, but got float\n",
    "#  나오는 현상 -> 랜덤 false로 했는데 발생할 때 있고 아닐 때 있음\n",
    "# \"\"\"\n",
    "# date_iter = iter(loader)\n",
    "# for i in range(100):\n",
    "#     x = next(date_iter)\n",
    "#     print(i)\n",
    "#     # print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 04:10:39,022 No multiple GPUs\n",
      "2020-01-23 04:10:39,150 *** Run Training ***  Steps: [561633]\n",
      "2020-01-23 04:10:39,152 >>> current step: 0\n",
      "2020-01-23 04:10:55,557 >>> current step: 10\n",
      "2020-01-23 04:11:10,625 >>> current step: 20\n",
      "2020-01-23 04:11:25,761 >>> current step: 30\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 5.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 52, in default_collate\n    numel = sum([x.numel() for x in batch])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 52, in <listcomp>\n    numel = sum([x.numel() for x in batch])\nAttributeError: 'float' object has no attribute 'numel'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-44cd7607be51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_multiple_gpu_if_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/bench/faze/models/torch/faze/train.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self, network_key, verbose)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> current step: %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_current_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> Complete training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bench/faze/models/torch/faze/train.py\u001b[0m in \u001b[0;36mexecute_training_step\u001b[0;34m(self, step, network_key, verbose)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_input_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bench/faze/models/torch/faze/train.py\u001b[0m in \u001b[0;36mget_next_input_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0minput_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                 \u001b[0minput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>> data iterator exception: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 5.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 74, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 74, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 52, in default_collate\n    numel = sum([x.numel() for x in batch])\n  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/collate.py\", line 52, in <listcomp>\n    numel = sum([x.numel() for x in batch])\nAttributeError: 'float' object has no attribute 'numel'\n"
     ]
    }
   ],
   "source": [
    "ctx.use_multiple_gpu_if_available()\n",
    "ctx.run_train('ted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute_training_step(current_step)\n",
    "\n",
    "# if current_step % args.print_freq_train == args.print_freq_train - 1:\n",
    "#     conv1_wt_lr = optimizer.param_groups[0]['lr']\n",
    "#     running_loss_means = running_losses.means()\n",
    "#     logging.info('Losses at [%7d]: %s' %\n",
    "#                  (current_step + 1,\n",
    "#                   ', '.join(['%s: %.5f' % v\n",
    "#                              for v in running_loss_means.items()])))\n",
    "#     if args.use_tensorboard:\n",
    "#         tensorboard.add_scalar('train_lr', conv1_wt_lr, current_step + 1)\n",
    "#         for k, v in running_loss_means.items():\n",
    "#             tensorboard.add_scalar('train/' + k, v, current_step + 1)\n",
    "#     running_losses.reset()\n",
    "\n",
    "# # Print some timing statistics\n",
    "# if current_step % 100 == 99:\n",
    "#     if args.use_tensorboard:\n",
    "#         for k, v in running_timings.means().items():\n",
    "#             tensorboard.add_scalar('timing/' + k, v, current_step + 1)\n",
    "#     running_timings.reset()\n",
    "\n",
    "# # print some memory statistics\n",
    "# if current_step % 5000 == 0:\n",
    "#     for i in range(torch.cuda.device_count()):\n",
    "#         bytes = (torch.cuda.memory_allocated(device=i)\n",
    "#                  + torch.cuda.memory_cached(device=i))\n",
    "#         logging.info('GPU %d: probably allocated approximately %.2f GB' % (i, bytes / 1e9))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
