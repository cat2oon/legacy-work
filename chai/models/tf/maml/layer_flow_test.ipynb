{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduction\n",
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidGenerator():\n",
    "    def __init__(self, K=10, amplitude=None, phase=None):\n",
    "        self.K = K\n",
    "        self.sampled_points = None\n",
    "        self.amplitude = amplitude if amplitude else np.random.uniform(0.1, 5.0)\n",
    "        self.phase = phase if amplitude else np.random.uniform(0, np.pi)\n",
    "        self.x = self._sample_x()\n",
    "        \n",
    "    def _sample_x(self):\n",
    "        return np.random.uniform(-5, 5, self.K)\n",
    "    \n",
    "    def f(self, x):\n",
    "        return self.amplitude * np.sin(x - self.phase)\n",
    "\n",
    "    def batch(self, x = None, force_new=False):\n",
    "        if x is None:\n",
    "            if force_new:\n",
    "                x = self._sample_x()\n",
    "            else:\n",
    "                x = self.x\n",
    "        y = self.f(x)\n",
    "        y = y.astype(np.float32)\n",
    "        x = x.astype(np.float32)\n",
    "        return x[:, None], y[:, None]\n",
    "    \n",
    "    def equally_spaced_samples(self, K=None):\n",
    "        if K is None:\n",
    "            K = self.K\n",
    "        return self.batch(x=np.linspace(-5, 5, K))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(K, train_size=20000, test_size=10):\n",
    "    def _generate_dataset(size):\n",
    "        return [SinusoidGenerator(K=K) for _ in range(size)]\n",
    "    return _generate_dataset(train_size), _generate_dataset(test_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = keras.layers.Dense(40, input_shape=(1,))\n",
    "        self.hidden2 = keras.layers.Dense(40)\n",
    "        self.out = keras.layers.Dense(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = keras.activations.relu(self.hidden1(x))\n",
    "        x = keras.activations.relu(self.hidden2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(model, x):\n",
    "    copied_model = SineModel()\n",
    "    \n",
    "    # If we don't run this step the weights are not \"initialized\"\n",
    "    # and the gradients will not be computed.\n",
    "    copied_model.forward(tf.convert_to_tensor(x))\n",
    "    copied_model.set_weights(model.get_weights())\n",
    "    return copied_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(pred_y, y):\n",
    "    return tf.reduce_mean(keras.losses.mean_squared_error(y, pred_y))\n",
    "\n",
    "def np_to_tensor(list_of_numpy_objs):\n",
    "    return (tf.convert_to_tensor(obj) for obj in list_of_numpy_objs)\n",
    "    \n",
    "def compute_loss(model, x, y, loss_fn=loss_function):\n",
    "    logits = model.forward(x)\n",
    "    mse = loss_fn(y, logits)\n",
    "    return mse, logits\n",
    "\n",
    "def compute_gradients(model, x, y, loss_fn=loss_function):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss, _ = compute_loss(model, x, y, loss_fn)\n",
    "    return tape.gradient(loss, model.trainable_variables), loss\n",
    "\n",
    "def apply_gradients(optimizer, gradients, variables):\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "def train_batch(x, y, model, optimizer):\n",
    "    tensor_x, tensor_y = np_to_tensor((x, y))\n",
    "    gradients, loss = compute_gradients(model, tensor_x, tensor_y)\n",
    "    apply_gradients(optimizer, gradients, model.trainable_variables)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = generate_dataset(K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_maml(model, dataset, batch_size=1):\n",
    "    lr_inner=0.01\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    \n",
    "    \"\"\" trainable learning rate \"\"\"\n",
    "    llr = np.tile(lr_inner, (len(model.layers))).astype(np.float32)\n",
    "    llr = tf.Variable(llr, name='learned_lr')\n",
    "\n",
    "    \n",
    "    for _ in range(20):\n",
    "        total_loss = 0\n",
    "        losses = []\n",
    "        \n",
    "        for i, t in enumerate(random.sample(dataset, len(dataset))):\n",
    "            x, y = np_to_tensor(t.batch())\n",
    "            model.forward(x)  # run forward pass to initialize weights\n",
    "            \n",
    "            with tf.GradientTape() as test_tape:\n",
    "                with tf.GradientTape() as train_tape:\n",
    "                    train_loss, _ = compute_loss(model, x, y)\n",
    "                \n",
    "                gradients = train_tape.gradient(train_loss, model.trainable_variables)\n",
    "                model_copy = copy_model(model, x)\n",
    "                \n",
    "                # TASK LEARNING\n",
    "                k = 0\n",
    "                for j in range(len(model_copy.layers)):\n",
    "                    lr = llr[int(k/2)]\n",
    "                    model_copy.layers[j].kernel = tf.subtract(\n",
    "                        model.layers[j].kernel, tf.multiply(lr, gradients[k+0]))\n",
    "                    model_copy.layers[j].bias = tf.subtract(\n",
    "                        model.layers[j].bias,   tf.multiply(lr, gradients[k+1]))\n",
    "                    k += 2\n",
    "                \n",
    "                # Loss for Meta Learning\n",
    "                test_loss, logits = compute_loss(model_copy, x, y)\n",
    "            \n",
    "            theta_meta = model.trainable_variables + [llr]\n",
    "            gradients = test_tape.gradient(test_loss, theta_meta)\n",
    "            optimizer.apply_gradients(zip(gradients, theta_meta))\n",
    "            \n",
    "            total_loss += test_loss\n",
    "            loss = total_loss / (i+1.0)\n",
    "            losses.append(loss)\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print('Step {}: loss = {}'.format(i, loss))\n",
    "                print(llr.numpy())\n",
    "        plt.plot(losses)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.6287810802459717\n",
      "[0.01100003 0.01100003 0.01100003]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bcff3cca0b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmaml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSineModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_maml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-315bad5a2d65>\u001b[0m in \u001b[0;36mtrain_maml\u001b[0;34m(model, dataset, batch_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     model_copy.layers[j].kernel = tf.subtract(\n\u001b[0;32m---> 30\u001b[0;31m                         model.layers[j].kernel, tf.multiply(lr, gradients[k+0]))\n\u001b[0m\u001b[1;32m     31\u001b[0m                     model_copy.layers[j].bias = tf.subtract(\n\u001b[1;32m     32\u001b[0m                         model.layers[j].bias,   tf.multiply(lr, gradients[k+1]))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;31m# if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0;31m# This is the last remaining reference.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m       \u001b[0;32mdel\u001b[0m \u001b[0mreference_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexisting_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# weakref.ref(a) in _WeakObjectIdentityWrapper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maml = SineModel()\n",
    "train_maml(maml, train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
