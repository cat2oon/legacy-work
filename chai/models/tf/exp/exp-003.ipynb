{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp 001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from nets.sdnet import *\n",
    "from ds.seq3 import *\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "init_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu_memory_growth_mode(gpu_id=0):\n",
    "    import tensorflow as tf\n",
    "    # tf.config.gpu.set_per_process_memory_growth(True) --> TF 1.x\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if not gpus:\n",
    "        return\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_id], True)\n",
    "    except RuntimeError as e:\n",
    "        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "        print(e)\n",
    "        \n",
    "set_gpu_memory_growth_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def archive_weights(model):\n",
    "    return [(v.name, v.numpy()) for v in model.trainable_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loss_fn():\n",
    "    @tf.function\n",
    "    def gaze_loss(label, pred):\n",
    "        return tf.reduce_mean(tf.losses.mse(label, pred))\n",
    "\n",
    "    @tf.function\n",
    "    def cos_loss(label, pred):\n",
    "        cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
    "        return cosine_loss(label, pred)\n",
    "    \n",
    "    @tf.function\n",
    "    def euclidean_loss(label, pred):\n",
    "        square = tf.math.square(pred - label)\n",
    "        reduce_sum = tf.math.reduce_sum(square, axis=1)\n",
    "        dists = tf.math.sqrt(reduce_sum)\n",
    "        return tf.math.reduce_mean(dists)\n",
    "    \n",
    "    @tf.function\n",
    "    def compound_loss(label, pred):\n",
    "        pred_vec,  pred_xy  = tf.split(pred,  [3, 2], 1)\n",
    "        label_vec, label_xy = tf.split(label, [3, 2], 1)\n",
    "        xy_loss = gaze_loss(label_xy, pred_xy)\n",
    "        vec_loss = gaze_loss(label_vec, pred_vec)\n",
    "        xy_euc_loss = euclidean_loss(label_xy, pred_xy)\n",
    "        return xy_loss + vec_loss + xy_euc_loss\n",
    "    return compound_loss\n",
    " \n",
    "def get_mean_distance_metric():\n",
    "    def mean_distance(y_true, y_pred):\n",
    "        _,  pred_xy = tf.split(y_pred, [3, 2], 1)\n",
    "        _, label_xy = tf.split(y_true, [3, 2], 1)\n",
    "        square = tf.math.square(pred_xy - label_xy)\n",
    "        reduce_sum = tf.math.reduce_sum(square, axis=1)\n",
    "        dists = tf.math.sqrt(reduce_sum)\n",
    "        return tf.math.reduce_mean(dists)\n",
    "    return mean_distance\n",
    "    \n",
    "def make_model():\n",
    "    net = SDNet.create()\n",
    "    l = make_loss_fn()\n",
    "    o = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    m = [get_mean_distance_metric()]\n",
    "    net.compile(loss=l, optimizer=o, metrics=m)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(gc_root_path, profiles, batch_size=32):\n",
    "    data_bag = {}\n",
    "    for pid in profiles:\n",
    "        train = Sequence('train', pid, gc_root_path, batch_size=batch_size)\n",
    "        valid = Sequence('valid', pid, gc_root_path, batch_size=batch_size)\n",
    "        data_bag[pid] = { 't': train, 'v': valid }\n",
    "    \n",
    "    # sample shape show\n",
    "    v = data_bag[profiles[0]]['v']\n",
    "    inputs, targets = v[0]\n",
    "    for ins in inputs:\n",
    "        print(ins.shape)\n",
    "    \n",
    "    return data_bag\n",
    "\n",
    "def cross_eval(m, data_bag, profiles):\n",
    "    for pid in profiles:\n",
    "        bag = data_bag[pid]\n",
    "        t, v = bag['t'], bag['v']\n",
    "        loss, metrics = m.evaluate(v, verbose=1, max_queue_size=10, workers=4)\n",
    "        print(\"{} 평가\".format(pid, loss, metrics))\n",
    "        \n",
    "def ce():\n",
    "    cross_eval(model, data_bag, ps)\n",
    "\n",
    "def train_epoch(m, data_bag, profile_id, snapshots, epochs=1, shuffle=False):\n",
    "    bag = data_bag[profile_id]\n",
    "    res = m.fit_generator(bag['t'], validation_data=bag['v'], epochs=epochs, verbose=1, \n",
    "                          shuffle=shuffle)\n",
    "    w = archive_weights(model)\n",
    "    s = (profile_id, w, res)\n",
    "    snapshots.append(s)\n",
    "    return res\n",
    "\n",
    "def q(pid, epochs=1, at_once=False):\n",
    "    if not at_once:\n",
    "        for e in range(epochs):\n",
    "            res = train_epoch(model, data_bag, pid, snapshots, epochs=1)\n",
    "            print(\">>> P[{}]: e[{}] snapshot: [{}]\".format(pid, e, len(snapshots)-1))\n",
    "    else:\n",
    "        res = train_epoch(model, data_bag, pid, snapshots, epochs=epochs)\n",
    "        \n",
    "\n",
    "def compare(x, y):\n",
    "    num_entry = len(snapshots)\n",
    "    if x >= num_entry or y >= num_entry:\n",
    "        print(\"only:\", num_entry)\n",
    "        return\n",
    "    \n",
    "    w_x, w_y = snapshots[x][1], snapshots[y][1]\n",
    "    for i in range(0, len(w_x)):\n",
    "        draw_weight_compare(w_x, w_y, i, (8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = []\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 128, 1)\n",
      "(32, 64, 128, 1)\n",
      "(32, 9)\n",
      "(32, 9)\n",
      "(32,)\n",
      "(32, 8)\n",
      "(32, 3)\n"
     ]
    }
   ],
   "source": [
    "# ps = ['01744', '02334', '02700', '01054', '01055', '02666']\n",
    "ps = ['01050', '01051', '01054', '01055', '02666']\n",
    "# ps = ['02342', '02349', '02450', '01905', '01054', '01055']\n",
    "data_bag = load_dataset(\"/home/elvin/banner/mnt/ssd3/nps\", ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_bag['02666']['v'].visualize(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-ba0f9c6d6934>:29: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 38 steps, validate for 20 steps\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 14s 373ms/step - loss: 30.9904 - mean_distance: 5.0348 - val_loss: 25.7747 - val_mean_distance: 4.1959\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 17.9712 - mean_distance: 2.9657 - val_loss: 23.2543 - val_mean_distance: 3.7645\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 13.4097 - mean_distance: 2.3710 - val_loss: 13.4263 - val_mean_distance: 2.3097\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 11.3523 - mean_distance: 2.1352 - val_loss: 12.2031 - val_mean_distance: 2.3755\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 10.1271 - mean_distance: 2.0108 - val_loss: 11.8866 - val_mean_distance: 2.4678\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 8.9764 - mean_distance: 1.8465 - val_loss: 9.9705 - val_mean_distance: 2.1316\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 5s 123ms/step - loss: 8.3676 - mean_distance: 1.7969 - val_loss: 9.6679 - val_mean_distance: 2.1489\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 7.7245 - mean_distance: 1.7222 - val_loss: 8.1249 - val_mean_distance: 1.8629\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 7.3236 - mean_distance: 1.6931 - val_loss: 7.8417 - val_mean_distance: 1.8267\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 7.0571 - mean_distance: 1.6944 - val_loss: 7.6144 - val_mean_distance: 1.8499\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 6.4049 - mean_distance: 1.5792 - val_loss: 7.0135 - val_mean_distance: 1.7575\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 5.8275 - mean_distance: 1.4535 - val_loss: 6.9756 - val_mean_distance: 1.7694\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 5.6787 - mean_distance: 1.4747 - val_loss: 6.6825 - val_mean_distance: 1.7810\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 5.5781 - mean_distance: 1.4955 - val_loss: 6.9999 - val_mean_distance: 1.9213\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 5.3242 - mean_distance: 1.4641 - val_loss: 6.3913 - val_mean_distance: 1.8023\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 4.9870 - mean_distance: 1.3965 - val_loss: 6.0776 - val_mean_distance: 1.7241\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.9610 - mean_distance: 1.4403 - val_loss: 6.7024 - val_mean_distance: 1.9009\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 4.6908 - mean_distance: 1.3772 - val_loss: 6.4037 - val_mean_distance: 1.8890\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.6349 - mean_distance: 1.3976 - val_loss: 6.1227 - val_mean_distance: 1.7728\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.6142 - mean_distance: 1.4101 - val_loss: 6.1920 - val_mean_distance: 1.8724\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.4378 - mean_distance: 1.3791 - val_loss: 5.8747 - val_mean_distance: 1.8032\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 4.4456 - mean_distance: 1.4173 - val_loss: 6.1800 - val_mean_distance: 1.8928\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 4.3796 - mean_distance: 1.4143 - val_loss: 5.6305 - val_mean_distance: 1.7571\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.4345 - mean_distance: 1.4645 - val_loss: 5.5030 - val_mean_distance: 1.7444\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.3792 - mean_distance: 1.4680 - val_loss: 5.4388 - val_mean_distance: 1.7256\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 5s 124ms/step - loss: 4.3091 - mean_distance: 1.4407 - val_loss: 5.4421 - val_mean_distance: 1.7562\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.3383 - mean_distance: 1.4764 - val_loss: 5.6716 - val_mean_distance: 1.8497\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 5s 126ms/step - loss: 4.1012 - mean_distance: 1.4068 - val_loss: 5.4736 - val_mean_distance: 1.7767\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 3.8657 - mean_distance: 1.3299 - val_loss: 5.7107 - val_mean_distance: 1.8765\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 5s 125ms/step - loss: 3.7725 - mean_distance: 1.3152 - val_loss: 5.6090 - val_mean_distance: 1.8567\n"
     ]
    }
   ],
   "source": [
    "q(ps[1], 30, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 - 2s\n"
     ]
    }
   ],
   "source": [
    "v = data_bag['01054']['v']\n",
    "res = model.predict(v, verbose=2, max_queue_size=10, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 14.0756 - mean_distance: 3.7177\n",
      "01050 평가\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 5.4799 - mean_distance: 1.7967\n",
      "01051 평가\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "31/31 [==============================] - 1s 26ms/step - loss: 12.0587 - mean_distance: 3.3572\n",
      "01054 평가\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "29/29 [==============================] - 1s 26ms/step - loss: 12.3830 - mean_distance: 3.4859\n",
      "01055 평가\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "24/24 [==============================] - 1s 26ms/step - loss: 8.3908 - mean_distance: 2.6378\n",
      "02666 평가\n"
     ]
    }
   ],
   "source": [
    "ce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only: 1\n"
     ]
    }
   ],
   "source": [
    "compare(34, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웨이트 변화량 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(x, y, eps=1e-08):\n",
    "    norm_x = np.linalg.norm(x) + eps \n",
    "    norm_y = np.linalg.norm(y) + eps\n",
    "    return np.dot(x, y) / (norm_x * norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_weight_compare(w_x, w_y, idx, fs=(4,4)):\n",
    "    # select layer\n",
    "    wx_name, x = w_x[idx]\n",
    "    wy_name, y = w_y[idx]\n",
    "    \n",
    "    if 'norm' in wx_name:\n",
    "        return\n",
    "    \n",
    "    print(\">>> name:{:20s} weight shape:\".format(wx_name), x.shape)\n",
    "    \n",
    "    x, y = np.squeeze(x), np.squeeze(y)\n",
    "    \n",
    "    # weight reshape\n",
    "    if len(x.shape) < 2:\n",
    "        x = x.reshape(2, int(x.shape[-1]/2))\n",
    "        y = y.reshape(2, int(y.shape[-1]/2))\n",
    "    else:\n",
    "        x = x.reshape(np.prod(x.shape[:-1]), x.shape[-1])\n",
    "        y = y.reshape(np.prod(y.shape[:-1]), y.shape[-1])\n",
    "    \n",
    "    if np.prod(x.shape) < 8 and 'bias' not in wx_name:\n",
    "        print(\"[w_x]:\", x.T)\n",
    "        print(\"[w_y]:\", y.T)\n",
    "        \n",
    "    # full - weight similarity\n",
    "    sim = np.around(cos_sim(x.flatten(), y.flatten()), decimals=4)\n",
    "    \n",
    "    # normalize\n",
    "    avg_x, avg_y = np.mean(x), np.mean(y)\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    min_y, max_y = np.min(y), np.max(y)\n",
    "    \n",
    "    x = (x - avg_x) / (max_x - min_x)\n",
    "    y = (y - avg_y) / (max_y - min_y)\n",
    "    x = x / np.linalg.norm(x)\n",
    "    y = y / np.linalg.norm(y)\n",
    "    \n",
    "    # compute diff\n",
    "    d = np.absolute(x - y)\n",
    "    s = np.around(np.mean(d) * 1000, decimals=5)\n",
    "    \n",
    "    # if 'final' in wx_name:\n",
    "    #     print(np.around(d, decimals=3))\n",
    "    \n",
    "    cm = 'hot'\n",
    "    plt.figure(figsize=fs)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(x, cmap=plt.get_cmap(cm))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y, cmap=plt.get_cmap(cm))\n",
    "    plt.title('COS-Sim: {}'.format(sim))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('R: {}'.format(s))\n",
    "    plt.imshow(d, cmap=plt.get_cmap(cm))\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
