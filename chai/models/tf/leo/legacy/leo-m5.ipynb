{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "from matrix import *\n",
    "from context import *\n",
    "from nets.gvm import *\n",
    "from ds.m5 import *\n",
    "from ds.data_utils import *\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gpu_memory_growth_mode(gpu_id=0):\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_id], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "set_gpu_memory_growth_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seed' : 1234,\n",
    "    'use_64bits': False,\n",
    "    \n",
    "    \"img_size_x\": 96,\n",
    "    \"img_size_y\": 64,\n",
    "    \"whole_eye_image_x\":96,\n",
    "    \"whole_eye_image_y\":48,\n",
    "    \"n_channel\": 3,\n",
    "    \n",
    "    \"batch_size\": 48,\n",
    "    \"num_epochs\": 100,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \n",
    "    \"ds_base_path\": '/home/elvin/banner/mnt/ssd3/everyone-norm',\n",
    "    \"data_path\": '/home/elvin/banner/mnt/ssd3/everyone-norm/valid/',\n",
    "}\n",
    "\n",
    "ctx = Context.create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "net = M4(ctx)\n",
    "net.load('sp-norm-61.hdf5')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(ctx.ds_base_path, \"train\", \"tfrecord4\")\n",
    "valid_path = os.path.join(ctx.ds_base_path, \"valid\", \"tfrecord4\")\n",
    "train_tf_paths = grep_files(train_path, '*.tfrecords')\n",
    "valid_tf_paths = grep_files(valid_path, '*.tfrecords')\n",
    "\n",
    "print(len(train_tf_paths))\n",
    "print(len(valid_tf_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(serialized_item):\n",
    "    record = tf.io.parse_example(\n",
    "        serialized_item,\n",
    "        features={\n",
    "            'subject' : tf.io.FixedLenFeature([], tf.string),\n",
    "            'frame'   : tf.io.FixedLenFeature([], tf.string),\n",
    "            'img_re'  : tf.io.VarLenFeature(tf.string),\n",
    "            'img_le'  : tf.io.VarLenFeature(tf.string),\n",
    "            'img_we'  : tf.io.VarLenFeature(tf.string),\n",
    "            'gaze'    : tf.io.FixedLenFeature([6], tf.float32),\n",
    "            'eyes'    : tf.io.FixedLenFeature([6], tf.float32),\n",
    "            'poses'   : tf.io.FixedLenFeature([9], tf.float32),\n",
    "            'rR'      : tf.io.FixedLenFeature([9], tf.float32),\n",
    "            'lR'      : tf.io.FixedLenFeature([9], tf.float32),\n",
    "            'cR'      : tf.io.FixedLenFeature([9], tf.float32),\n",
    "            'gaze2d'  : tf.io.FixedLenFeature([3], tf.float32),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    img_re = record['img_re'].values[0]\n",
    "    img_re = tf.image.decode_jpeg(img_re)[16:-16,:,::-1]\n",
    "    img_re = tf.image.convert_image_dtype(img_re, tf.float32)\n",
    "\n",
    "    img_le = record['img_le'].values[0]\n",
    "    img_le = tf.image.decode_jpeg(img_le)[16:-16,:,::-1]\n",
    "    img_le = tf.image.convert_image_dtype(img_le, tf.float32)\n",
    "\n",
    "    img_we = record['img_we'].values[0]\n",
    "    img_we = tf.image.decode_jpeg(img_we)[:,:,::-1]\n",
    "    img_we = tf.image.convert_image_dtype(img_we, tf.float32)\n",
    "\n",
    "    gaze_r  = record['gaze'][0:3]\n",
    "    gaze_l  = record['gaze'][3:6]\n",
    "    gaze_cm = record['gaze2d'] / 10\n",
    "\n",
    "    outputs = (gaze_r, gaze_l, gaze_cm, gaze_cm, gaze_cm)\n",
    "    return (img_re, img_le, img_we, record['eyes'], record['poses'], \n",
    "              record['rR'], record['lR'], record['gaze2d'], record['gaze2d']), outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1af692db1efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tfrecord4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ai/models/tf/leo/ds/m5.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, phase, epoch, subject_batched, batch_number)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai/models/tf/leo/ds/m5.py\u001b[0m in \u001b[0;36m_calculate_length\u001b[0;34m(self, config, phase, subject_batched)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgaze_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                     \u001b[0mnum_frames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "dr = DatasetReader(ctx, phase='tfrecord4', epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = tf.data.TFRecordDataset(train_tf_paths)\n",
    "# valid_ds = tf.data.TFRecordDataset(valid_tf_paths)\n",
    "# train_seq = train_ds.map(decode, num_parallel_calls=16).prefetch(tf.data.experimental.AUTOTUNE).batch(16)\n",
    "# valid_seq = valid_ds.map(decode, num_parallel_calls=16).prefetch(tf.data.experimental.AUTOTUNE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.model.fit(train_seq, shuffle=False, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = net.model.predict(valid_seq_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
