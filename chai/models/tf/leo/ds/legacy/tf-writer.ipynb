{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Writer for Norm-Split 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import os, json, glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_output = '/mnt/sata3/everyone-tfrecord2'\n",
    "dir_input = '/mnt/sata4/everyone'\n",
    "image_dir = 'frames'\n",
    "json_dir = 'data'\n",
    "landmarkd_dir = 'landmark2'\n",
    "tfrecord_dir = 'tfrecord2'\n",
    "temptfrecord_dir = 'temp_record'\n",
    "\n",
    "phases = ['train', 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStandard3DFacePoints():\n",
    "    faceModel = 'standard3DFace.json'\n",
    "\n",
    "    if not os.path.isfile(faceModel):\n",
    "        print(faceModel, 'not found!')\n",
    "        return None\n",
    "\n",
    "    with open(faceModel, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    eye_right   = np.array( data['eye_right'],   dtype='float32')\n",
    "    eye_left    = np.array( data['eye_left'],    dtype='float32')\n",
    "    nose        = np.array( data['nose'],        dtype='float32')\n",
    "    nose_bottom = np.array( data['nose_bottom'], dtype='float32')\n",
    "    jaws        = np.array( data['jaws'],        dtype='float32')\n",
    "\n",
    "    return np.vstack((eye_right, eye_left, nose, nose_bottom, jaws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noinspection PyShadowingNames\n",
    "def estimateHeadPosition(refined_landmarks, position, camera_matrix, camera_distortion):\n",
    "#     print('refined_landmarks:', refined_landmarks, 'position:',position, 'camera_matrix:',camera_matrix, 'camera_distortion:', camera_distortion)\n",
    "    ret, rvec, tvec = cv2.solvePnP(position, refined_landmarks,\n",
    "                                   camera_matrix, camera_distortion, flags=cv2.SOLVEPNP_EPNP)\n",
    "    ret, rvec, tvec = cv2.solvePnP(position, refined_landmarks, camera_matrix, camera_distortion, rvec, tvec, True)\n",
    "\n",
    "    return rvec, tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plane(p1, p2, p3):\n",
    "    # These two vectors are in the plane\n",
    "    v1 = p3 - p1\n",
    "    v2 = p2 - p1\n",
    "\n",
    "    # the cross product is a vector normal to the plane\n",
    "    cp = np.cross(v1, v2)\n",
    "    a, b, c = cp\n",
    "\n",
    "    # This evaluates a * x3 + b * y3 + c * z3 which equals d\n",
    "    d = np.dot(cp, p3)\n",
    "\n",
    "    # The equation is ax + by + cz = d\n",
    "    # But we want to have ax + by + c = z\n",
    "#     print('The equation is {0}x + {1}y + {2}z = {3}'.format(a, b, c, d))\n",
    "    a = - a / c\n",
    "    b = - b / c\n",
    "    c = d / c\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_R(rotation_matrix, center):\n",
    "    distance = np.linalg.norm(center)\n",
    "    hRx = rotation_matrix[:, 0]\n",
    "    \n",
    "    forward = (center / distance).reshape(3)\n",
    "    \n",
    "    down = np.cross(forward, hRx)\n",
    "    down /= np.linalg.norm(down)\n",
    "    \n",
    "    right = np.cross(down, forward)\n",
    "    right /= np.linalg.norm(right)\n",
    "    \n",
    "    return np.c_[right, down, forward].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We need modified S that does not scale but move Z by k distance\n",
    "    make plane that formed by le, re, nose_tip\n",
    "    ax + by + c = z\n",
    "    S = |   1      0      0  |\n",
    "        |   0      1      0  |\n",
    "        | -ak/c  -bk/c  1+k/c|\n",
    "\n",
    "    S moves (x, y, z) to (x, y, z + k)\n",
    "'''\n",
    "\n",
    "def calculate_S(pt1, pt2, pt3, R, target_distance):\n",
    "    pt1 = np.dot(R, pt1)\n",
    "    pt2 = np.dot(R, pt2)\n",
    "    pt3 = np.dot(R, pt3)\n",
    "    \n",
    "    p1 = np.reshape(pt1, 3)\n",
    "    p2 = np.reshape(pt2, 3)\n",
    "    p3 = np.reshape(pt3, 3)\n",
    "    \n",
    "    a, b, c = get_plane(p1, p2, p3)\n",
    "    k = target_distance - c\n",
    "    \n",
    "    S = np.array([\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 0.0],\n",
    "        [-a*k/c, -b*k/c, 1+k/c],\n",
    "    ])\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(json_path, image_path):\n",
    "\n",
    "    # load image and data files\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if not os.path.isfile(image_path):\n",
    "        print(image_path, 'not exists!')\n",
    "        return None\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "#     with open(landmark_path, 'r') as f:\n",
    "#         landmark_data = json.load(f)\n",
    "\n",
    "\n",
    "    params, dists = getFocalLengthAndDistortion(data['deviceName'])\n",
    "    if params is None:\n",
    "        return None\n",
    "\n",
    "    fx, fy = params[0], params[1]\n",
    "    if image.shape[1] > image.shape[0]:  # width > height\n",
    "        cx, cy = params[3], params[2]\n",
    "    else:\n",
    "        cx, cy = params[2], params[3]\n",
    "\n",
    "    camera_distortion = np.hstack((dists, 0))\n",
    "\n",
    "    camera_matrix = np.array([\n",
    "        [fx,  0, cx],\n",
    "        [ 0, fy, cy],\n",
    "        [ 0,  0, 1 ]\n",
    "    ])\n",
    "\n",
    "    landmarks = getLandmarksFromJson(data)\n",
    "\n",
    "    if landmarks is None:\n",
    "        print(image_path, 'has no landmark information!')\n",
    "        return None\n",
    "\n",
    "    landmarks, face_3d = removeOutsideImage(image, landmarks, copy.deepcopy(standardFace))\n",
    "    # make to 3-D array\n",
    "    landmarks = landmarks.reshape(-1, 1, 2)\n",
    "    face_3d = face_3d.reshape(-1, 1, 3)\n",
    "\n",
    "    lookat = np.array([-data['XCam'], -data['YCam'], 0])\n",
    "    # cm to mm\n",
    "    lookat = lookat * 10\n",
    "    lookat = lookat.reshape((3, 1))\n",
    "    \n",
    "    return image, camera_matrix, camera_distortion, landmarks, face_3d, lookat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataAndGaze(image, face, camera_matrix, look_vector, head_rotate, landmarks):\n",
    "    # normalizing face area\n",
    "    nose_tip = face[:, 15].reshape((3, 1))\n",
    "    eye_center = np.array([sum(x) for x in face[:, 0:12]]) / 12\n",
    "    re = np.array([sum(x) for x in face[:, 0:6]]) / 6\n",
    "    le = np.array([sum(x) for x in face[:, 6:12]]) / 6\n",
    "\n",
    "    center = eye_center.reshape((3, 1))\n",
    "    \n",
    "    gaze_data = []\n",
    "    warped_image = []\n",
    "    R_list = []\n",
    "    for eye in [re, le]:\n",
    "        R = get_R(head_rotate, eye)\n",
    "        S = calculate_S(re, le, nose_tip, R, normalize_distance)\n",
    "        W = np.dot(np.dot(eye_norm, S), np.dot(R, np.linalg.inv(camera_matrix)))  # transformation matrix\n",
    "        image_warped = cv2.warpPerspective(image, W, normalize_eye_size)  # image normalization\n",
    "\n",
    "        eye = eye.reshape((3, 1))\n",
    "        g = look_vector - eye\n",
    "        g = np.dot(R, g)\n",
    "        g = g / (-g[2])\n",
    "        \n",
    "        warped_image.append(image_warped)\n",
    "        gaze_data.append(g)\n",
    "        R_list.append(R)\n",
    "        if debug_print:\n",
    "            drawCVImage(image_warped)\n",
    "    \n",
    "    center = (nose_tip + eye_center.reshape((3, 1))) / 2\n",
    "    R = get_R(head_rotate, center)\n",
    "    S = calculate_S(re, le, nose_tip, R, normalize_distance)\n",
    "    W = np.dot(np.dot(face_norm, S), np.dot(R, np.linalg.inv(camera_matrix)))  # transformation matrix\n",
    "    image_warped = cv2.warpPerspective(image, W, normalize_face_size)  # image normalization\n",
    "    transformed_lks = cv2.perspectiveTransform(landmarks, W)\n",
    "\n",
    "    warped_image.append(image_warped)\n",
    "    R_list.append(R)\n",
    "    if debug_print:\n",
    "        drawLandmarks(image_warped, transformed_lks.reshape((-1, 2)))\n",
    "\n",
    "#     right_gaze = gaze_data[0]\n",
    "#     right_eye = eye_right.reshape((3, 1))\n",
    "#     original_right_gaze = np.dot(np.linalg.inv(R), right_gaze)\n",
    "#     multiplier = - np.divide(right_eye[2], original_right_gaze[2])\n",
    "#     target = np.add(right_eye, np.multiply(original_right_gaze, multiplier))\n",
    "#     print('right_gaze:', right_gaze, ', right_eye:', right_eye, ', target(re):', target, ', target(true)', look_vector)\n",
    "    \n",
    "    return warped_image, np.array(gaze_data), R_list #cv2.Rodrigues(np.dot(R, hR))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize(subject, frame):\n",
    "    name = subject + '_' + frame\n",
    "    json_path = os.path.join(input_json_dir, subject, name) + '.json'\n",
    "    image_path = os.path.join(input_image_dir, subject, name) + '.jpg'\n",
    "#     landmark_path = os.path.join(input_landmark_dir, data_name) + '.json'\n",
    "    \n",
    "    try:\n",
    "        image, camera_matrix, camera_distortion, landmarks, face_3d, lookat = read_data(json_path, image_path)\n",
    "    except:\n",
    "        print('Failed to read data : ', data_name)\n",
    "        return None\n",
    "    \n",
    "    # undistort landmark points and image\n",
    "    landmarks = cv2.undistortPoints(landmarks, camera_matrix, camera_distortion, P=camera_matrix)\n",
    "    image_undistorted = cv2.undistort(image, camera_matrix, camera_distortion)\n",
    "    \n",
    "#     drawCVImage(image)\n",
    "    # pnp R and T\n",
    "    hr, ht = estimateHeadPosition(landmarks, face_3d, camera_matrix, camera_distortion)\n",
    "    face_3d = face_3d.reshape(-1, 3).T\n",
    "    ht = ht.reshape((3, 1))\n",
    "\n",
    "    # Rodrigues expression to 3x3 rotation matrix\n",
    "    hR = cv2.Rodrigues(hr)[0]  # rotation matrix\n",
    "    translate = ht.reshape((3, 1))\n",
    "    face = np.dot(hR, face_3d) + translate  # 3D positions of facial landmarks\n",
    "\n",
    "    # warped image, rotated gaze vector, face R, S, W, 3D face points\n",
    "    image_warped, gaze_vector, R = normalizeDataAndGaze(image_undistorted, \n",
    "                                                        face,\n",
    "                                                        camera_matrix,\n",
    "                                                        lookat,\n",
    "                                                        hR,\n",
    "                                                        landmarks)\n",
    "\n",
    "\n",
    "    eye_right = np.array([sum(x) for x in face[:, 0:6]]) / 6\n",
    "    eye_left = np.array([sum(x) for x in face[:, 6:12]]) / 6\n",
    "    \n",
    "#     if abs(hR[2,0]) + abs(hR[2,1]) > abs(hR[2,2]) or hR[2,2]< 0:\n",
    "#         print(hR)\n",
    "#         drawCVImage(image)\n",
    "#         drawLandmarks(image_undistorted, np.reshape(landmarks, [-1, 2]))\n",
    "    \n",
    "    right_eye_pose = cv2.Rodrigues(np.dot(R[0], hR))[0]\n",
    "    left_eye_pose = cv2.Rodrigues(np.dot(R[1], hR))[0]\n",
    "    face_pose = cv2.Rodrigues(np.dot(R[2], hR))[0]\n",
    "    \n",
    "    \n",
    "    eyes = np.append(eye_right, eye_left)\n",
    "    poses = np.reshape(np.concatenate((right_eye_pose, left_eye_pose, face_pose), axis=0), (-1))\n",
    "\n",
    "#     if out_print:\n",
    "#         print(record_data['gaze_pixel'])\n",
    "#         drawCVImage(image)\n",
    "#         print(record_data['orientation'])\n",
    "#         print(eyes)    \n",
    "#         print(eye_poses)\n",
    "\n",
    "    return image_warped, gaze_vector, eyes, poses, R[0], R[1], R[2], lookat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _bytes_feature2(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def make_example(subject_name, frame_name, re, le, we, gaze, eyes, poses, rR, lR, cR, gaze2d):\n",
    "    feature = {\n",
    "        'subject': _bytes_feature(subject_name),\n",
    "        'frame': _bytes_feature(frame_name),\n",
    "        'img_re': _bytes_feature(re),\n",
    "        'img_le': _bytes_feature(le),\n",
    "        'img_we': _bytes_feature(we),\n",
    "        'gaze': _float_feature(np.reshape(gaze, (-1)).tolist()),\n",
    "        'eyes': _float_feature(np.reshape(eyes, (-1)).tolist()),\n",
    "        'poses': _float_feature(np.reshape(poses, (-1)).tolist()),\n",
    "        'rR': _float_feature(np.reshape(rR, (-1)).tolist()),\n",
    "        'lR': _float_feature(np.reshape(lR, (-1)).tolist()),\n",
    "        'cR': _float_feature(np.reshape(cR, (-1)).tolist()),\n",
    "        'gaze2d': _float_feature(np.reshape(gaze2d, (-1)).tolist()),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def _parse_image_function(example_raw):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_raw, image_feature_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
