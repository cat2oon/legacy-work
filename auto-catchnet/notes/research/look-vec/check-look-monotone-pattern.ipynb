{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optical axis monotone pattern vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_modules():\n",
    "    sys.path.append(\"../../../\")\n",
    "    %run ../../../ds/device/nexus5x.py\n",
    "    \n",
    "    %run ../../../al/actor/face.py\n",
    "    %run ../../../al/feature/face/imps/candide.py\n",
    "    %run ../../../ac/images/loader.py\n",
    "    %run ../../../ac/images/filters/filters.py\n",
    "    %run ../../../ac/math/angles.py\n",
    "    %run ../../../ac/visualizer/plotter.py\n",
    "    %run ../../../ac/visualizer/trajectory.py\n",
    "    \n",
    "    %run ../../../ds/unity/model/eye_params.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "load_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: abstract model weight path configuration \n",
    "candide_path=\"/home/chy/archive-model/candide/candide.npz\"\n",
    "land_mark_path=\"/home/chy/archive-model/candide/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "model_path = \"/home/chy/archive-model/incubator/lookvec/lvm-pilot.json\"\n",
    "weight_path = \"/home/chy/archive-model/incubator/lookvec/lv-01-0.0172724.hdf5\"\n",
    "\n",
    "# img_src_path = \"/media/chy/1326657F605F16F2/bench/vc-one/10d114QXIViemIAC/record-3-0-0\"\n",
    "img_src_path = \"/media/chy/1326657F605F16F2/bench/vc-one/10d114QXIViemIAC/200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.1 (s)\n",
      "cpu elapsed time: 0.1 (s)\n",
      "*** img samples 10 ***\n"
     ]
    }
   ],
   "source": [
    "face_imgs = load_images(img_src_path)\n",
    "print(\"*** img samples {} ***\".format(len(face_imgs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candide = Candide(candide_path, land_mark_path)\n",
    "camera = MobileNexus5X.get_camera()\n",
    "\n",
    "opt_predictor = OpticalAxisPredictor()\n",
    "opt_predictor.load_model(model_path, weight_path)\n",
    "face_model = FaceModel(candide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_dir_path = \"/home/chy/dev-bench/auto-catch/notes/research/look-vec/dissection/samples/\"\n",
    "\n",
    "def report(face:FaceActor):\n",
    "    ov = face.r_opt_vec\n",
    "    lv = face.head_pose_in_degree\n",
    "    # a, b, r = unit_vec_to_angles(ov)\n",
    "    # look_angs = \"({} {} {})\".format(a,b,r)\n",
    "    # ax = show_image(face.r_eye_img, fig_size=(4,4), title=lv)\n",
    "    ax = show_image(face.frame, fig_size=(4,4), title=lv)\n",
    "    \n",
    "def archive(idx, face:FaceActor):\n",
    "    img_path = \"{}/{}.jpg\".format(archive_dir_path, idx)\n",
    "    meta_path = \"{}/{}.npy\".format(archive_dir_path, idx)\n",
    "    cv2.imwrite(img_path, face.r_eye_img)\n",
    "    np.save(meta_path, face.head_pose_in_degree)\n",
    "        \n",
    "def mark_target(face, trajectory):\n",
    "    r_opt_vec = face.r_opt_vec\n",
    "    l_tar, r_tar = face.compute_gaze_target_pos_in_mm(r_opt_vec, r_opt_vec)\n",
    "    trajectory.mark(idx, r_tar[0], r_tar[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = []\n",
    "for img in face_imgs:\n",
    "    f = FaceActor(camera, face_model, opt_predictor, reference_fissure_length=25)\n",
    "    f.match(img)\n",
    "    f.analysis()\n",
    "    faces.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, face in enumerate(faces):\n",
    "    # report(face)\n",
    "    archive(i, face)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doodles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 11.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num_to_eye_param(1310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"{}/{}.npy\".format(archive_dir_path, 73)\n",
    "np.save(meta_path, np.array([321.3775, 182.4169, 0.000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
